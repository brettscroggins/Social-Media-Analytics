{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hony_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df['image_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates('image_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_url</th>\n",
       "      <th>post</th>\n",
       "      <th>no_likes</th>\n",
       "      <th>no_comments</th>\n",
       "      <th>image_labels</th>\n",
       "      <th>image_text</th>\n",
       "      <th>web_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/e49...</td>\n",
       "      <td>“I didn’t get accepted into any of the univers...</td>\n",
       "      <td>493.6k</td>\n",
       "      <td>3,806</td>\n",
       "      <td>footwear fashion accessory jeans shoulder shoe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Casa Adela Brandon Stanton New York City Bingh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/2ea...</td>\n",
       "      <td>\"I'm trying to live my life without conflict s...</td>\n",
       "      <td>268k</td>\n",
       "      <td>2,714</td>\n",
       "      <td>sitting vehicle temple headgear street health ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brandon Stanton New York City India Black Pant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/158...</td>\n",
       "      <td>“I was a full time housewife. I kept mostly to...</td>\n",
       "      <td>411.7k</td>\n",
       "      <td>4,103</td>\n",
       "      <td>woman facial expression lady smile snapshot gi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York City Felines of New York: A Glimpse I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/053...</td>\n",
       "      <td>\"I don't know how old I am.\" (Mumbai, India)</td>\n",
       "      <td>451.4k</td>\n",
       "      <td>5,207</td>\n",
       "      <td>face facial expression yellow head smile eye t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India Humans of New York Humans of New York: S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/808...</td>\n",
       "      <td>“I resented my mother for the longest time. Sh...</td>\n",
       "      <td>237.2k</td>\n",
       "      <td>1,201</td>\n",
       "      <td>hand finger nail arm jewellery ring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York City Sadhana H. Varshney Mumbai Human...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           image_url  \\\n",
       "0  https://instagram.fftw1-1.fna.fbcdn.net/vp/e49...   \n",
       "1  https://instagram.fftw1-1.fna.fbcdn.net/vp/2ea...   \n",
       "2  https://instagram.fftw1-1.fna.fbcdn.net/vp/158...   \n",
       "3  https://instagram.fftw1-1.fna.fbcdn.net/vp/053...   \n",
       "4  https://instagram.fftw1-1.fna.fbcdn.net/vp/808...   \n",
       "\n",
       "                                                post no_likes no_comments  \\\n",
       "0  “I didn’t get accepted into any of the univers...   493.6k       3,806   \n",
       "1  \"I'm trying to live my life without conflict s...     268k       2,714   \n",
       "2  “I was a full time housewife. I kept mostly to...   411.7k       4,103   \n",
       "3       \"I don't know how old I am.\" (Mumbai, India)   451.4k       5,207   \n",
       "4  “I resented my mother for the longest time. Sh...   237.2k       1,201   \n",
       "\n",
       "                                        image_labels image_text  \\\n",
       "0  footwear fashion accessory jeans shoulder shoe...        NaN   \n",
       "1  sitting vehicle temple headgear street health ...        NaN   \n",
       "2  woman facial expression lady smile snapshot gi...        NaN   \n",
       "3  face facial expression yellow head smile eye t...        NaN   \n",
       "4                hand finger nail arm jewellery ring        NaN   \n",
       "\n",
       "                                        web_entities  \n",
       "0  Casa Adela Brandon Stanton New York City Bingh...  \n",
       "1  Brandon Stanton New York City India Black Pant...  \n",
       "2  New York City Felines of New York: A Glimpse I...  \n",
       "3  India Humans of New York Humans of New York: S...  \n",
       "4  New York City Sadhana H. Varshney Mumbai Human...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_location(x):\n",
    "    pattern = \"\\(\\D*\\)\" # non-digits within parentheses (excludes instances with multiple posts, e.g. \"Caption...(2/3)\")\n",
    "    match = re.findall(pattern, x)\n",
    "    if len(match) == 0:\n",
    "        return (\"NYC, USA\")\n",
    "    else:\n",
    "        return match[len(match)-1].lstrip(\"(\").rstrip(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NYC, USA                                                              326\n",
       "Mumbai, India                                                          29\n",
       "Jaipur, India                                                          27\n",
       "São Paulo, Brazil                                                      25\n",
       "Rio de Janeiro, Brazil                                                 20\n",
       "St. Petersburg, Russia                                                 19\n",
       "Bogotá, Colombia                                                       18\n",
       "Udaipur, India                                                         18\n",
       "Moscow, Russia                                                         15\n",
       "Dhaka, Bangladesh                                                      15\n",
       "Santiago, Chile                                                        13\n",
       "Jakarta, Indonesia                                                     11\n",
       "Montevideo, Uruguay                                                     9\n",
       "Cordoba, Argentina                                                      8\n",
       "Lima, Peru                                                              8\n",
       "Medellín, Colombia                                                      6\n",
       "Calcutta, India                                                         6\n",
       "Rosario, Argentina                                                      5\n",
       "Valparaíso, Chile                                                       3\n",
       "Lençóis, Brazil                                                         3\n",
       "Salvador, Brazil                                                        3\n",
       "Buenos Aires, Argentina                                                 3\n",
       "Bariloche, Argentina                                                    3\n",
       "San Carlos de Bariloche, Argentina                                      1\n",
       "Jakarta Indonesia                                                       1\n",
       "See previous story                                                      1\n",
       "Link to entire collection of Met Gala stories can be found in bio.      1\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['location'] = df['post'].map(get_location)\n",
    "df['location'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all likes in thousands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def likes_num(x):\n",
    "    match = re.findall('k',x)\n",
    "    if len(match) == 0:\n",
    "        return int(float(x.rstrip('m'))*1000)\n",
    "    else: \n",
    "        return int(float(x.rstrip('k')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_url</th>\n",
       "      <th>post</th>\n",
       "      <th>no_likes</th>\n",
       "      <th>no_comments</th>\n",
       "      <th>image_labels</th>\n",
       "      <th>image_text</th>\n",
       "      <th>web_entities</th>\n",
       "      <th>location</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/e49...</td>\n",
       "      <td>“I didn’t get accepted into any of the univers...</td>\n",
       "      <td>493.6k</td>\n",
       "      <td>3,806</td>\n",
       "      <td>footwear fashion accessory jeans shoulder shoe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Casa Adela Brandon Stanton New York City Bingh...</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>493</td>\n",
       "      <td>3806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/2ea...</td>\n",
       "      <td>\"I'm trying to live my life without conflict s...</td>\n",
       "      <td>268k</td>\n",
       "      <td>2,714</td>\n",
       "      <td>sitting vehicle temple headgear street health ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brandon Stanton New York City India Black Pant...</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>268</td>\n",
       "      <td>2714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/158...</td>\n",
       "      <td>“I was a full time housewife. I kept mostly to...</td>\n",
       "      <td>411.7k</td>\n",
       "      <td>4,103</td>\n",
       "      <td>woman facial expression lady smile snapshot gi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York City Felines of New York: A Glimpse I...</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>411</td>\n",
       "      <td>4103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/053...</td>\n",
       "      <td>\"I don't know how old I am.\" (Mumbai, India)</td>\n",
       "      <td>451.4k</td>\n",
       "      <td>5,207</td>\n",
       "      <td>face facial expression yellow head smile eye t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India Humans of New York Humans of New York: S...</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>451</td>\n",
       "      <td>5207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/808...</td>\n",
       "      <td>“I resented my mother for the longest time. Sh...</td>\n",
       "      <td>237.2k</td>\n",
       "      <td>1,201</td>\n",
       "      <td>hand finger nail arm jewellery ring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York City Sadhana H. Varshney Mumbai Human...</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>237</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           image_url  \\\n",
       "0  https://instagram.fftw1-1.fna.fbcdn.net/vp/e49...   \n",
       "1  https://instagram.fftw1-1.fna.fbcdn.net/vp/2ea...   \n",
       "2  https://instagram.fftw1-1.fna.fbcdn.net/vp/158...   \n",
       "3  https://instagram.fftw1-1.fna.fbcdn.net/vp/053...   \n",
       "4  https://instagram.fftw1-1.fna.fbcdn.net/vp/808...   \n",
       "\n",
       "                                                post no_likes no_comments  \\\n",
       "0  “I didn’t get accepted into any of the univers...   493.6k       3,806   \n",
       "1  \"I'm trying to live my life without conflict s...     268k       2,714   \n",
       "2  “I was a full time housewife. I kept mostly to...   411.7k       4,103   \n",
       "3       \"I don't know how old I am.\" (Mumbai, India)   451.4k       5,207   \n",
       "4  “I resented my mother for the longest time. Sh...   237.2k       1,201   \n",
       "\n",
       "                                        image_labels image_text  \\\n",
       "0  footwear fashion accessory jeans shoulder shoe...        NaN   \n",
       "1  sitting vehicle temple headgear street health ...        NaN   \n",
       "2  woman facial expression lady smile snapshot gi...        NaN   \n",
       "3  face facial expression yellow head smile eye t...        NaN   \n",
       "4                hand finger nail arm jewellery ring        NaN   \n",
       "\n",
       "                                        web_entities       location  likes  \\\n",
       "0  Casa Adela Brandon Stanton New York City Bingh...  Mumbai, India    493   \n",
       "1  Brandon Stanton New York City India Black Pant...  Mumbai, India    268   \n",
       "2  New York City Felines of New York: A Glimpse I...  Mumbai, India    411   \n",
       "3  India Humans of New York Humans of New York: S...  Mumbai, India    451   \n",
       "4  New York City Sadhana H. Varshney Mumbai Human...  Mumbai, India    237   \n",
       "\n",
       "  comments  \n",
       "0     3806  \n",
       "1     2714  \n",
       "2     4103  \n",
       "3     5207  \n",
       "4     1201  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['likes'] = df['no_likes'].map(lambda x: likes_num(x))\n",
    "df['comments'] = df['no_comments'].map(lambda x: x.replace(\",\", \"\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    267\n",
       "0    205\n",
       "2     85\n",
       "3     28\n",
       "4      8\n",
       "6      3\n",
       "9      1\n",
       "Name: likes_decile, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['likes_decile'] = pd.cut(df['likes'],10, labels = False) # even spacing as opposed to qcut \n",
    "# 1 represents fewest likes\n",
    "df['likes_decile'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146.0, 252.0]     267\n",
       "(38.94, 146.0]     205\n",
       "(252.0, 358.0]      85\n",
       "(358.0, 464.0]      28\n",
       "(464.0, 570.0]       8\n",
       "(676.0, 782.0]       3\n",
       "(994.0, 1100.0]      1\n",
       "(888.0, 994.0]       0\n",
       "(782.0, 888.0]       0\n",
       "(570.0, 676.0]       0\n",
       "Name: likes, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bin values\n",
    "pd.cut(df['likes'],10).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math as m\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    doc = re.sub(r'[^\\w\\s]*', '', doc) \n",
    "    doc = re.sub(r'[\\s]+', ' ', doc)\n",
    "    doc = doc.lower().strip()\n",
    "    return doc\n",
    "\n",
    "df['words'] = df['post'].map(lambda x: clean(x).split())\n",
    "clean_docs = df['words'].tolist()\n",
    "# clean_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stopwords - probably want to add locations to the list because those still show up in words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stops = list(stopwords.words('english'))\n",
    "addtl_sw = ['one','got',\"im\",\"ive\",\"id\",'even','like','going'] \n",
    "\n",
    "def remove_stopwords(doc):\n",
    "    sw_doc = list()\n",
    "    for token in doc:\n",
    "        if not token in stops and not token in addtl_sw:\n",
    "            sw_doc.append(token)\n",
    "    return sw_doc\n",
    "            \n",
    "df['tokens'] = df['words'].map(lambda x: remove_stopwords(x))\n",
    "sw_token_docs = df['tokens'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_url</th>\n",
       "      <th>post</th>\n",
       "      <th>image_labels</th>\n",
       "      <th>image_text</th>\n",
       "      <th>web_entities</th>\n",
       "      <th>location</th>\n",
       "      <th>likes</th>\n",
       "      <th>comments</th>\n",
       "      <th>likes_decile</th>\n",
       "      <th>words</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/e49...</td>\n",
       "      <td>“I didn’t get accepted into any of the univers...</td>\n",
       "      <td>footwear fashion accessory jeans shoulder shoe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Casa Adela Brandon Stanton New York City Bingh...</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>493</td>\n",
       "      <td>3806</td>\n",
       "      <td>4</td>\n",
       "      <td>[i, didnt, get, accepted, into, any, of, the, ...</td>\n",
       "      <td>[didnt, get, accepted, universities, wanted, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/2ea...</td>\n",
       "      <td>\"I'm trying to live my life without conflict s...</td>\n",
       "      <td>sitting vehicle temple headgear street health ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brandon Stanton New York City India Black Pant...</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>268</td>\n",
       "      <td>2714</td>\n",
       "      <td>2</td>\n",
       "      <td>[im, trying, to, live, my, life, without, conf...</td>\n",
       "      <td>[im, trying, live, life, without, conflict, do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/158...</td>\n",
       "      <td>“I was a full time housewife. I kept mostly to...</td>\n",
       "      <td>woman facial expression lady smile snapshot gi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York City Felines of New York: A Glimpse I...</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>411</td>\n",
       "      <td>4103</td>\n",
       "      <td>3</td>\n",
       "      <td>[i, was, a, full, time, housewife, i, kept, mo...</td>\n",
       "      <td>[full, time, housewife, kept, mostly, shy, per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/053...</td>\n",
       "      <td>\"I don't know how old I am.\" (Mumbai, India)</td>\n",
       "      <td>face facial expression yellow head smile eye t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India Humans of New York Humans of New York: S...</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>451</td>\n",
       "      <td>5207</td>\n",
       "      <td>3</td>\n",
       "      <td>[i, dont, know, how, old, i, am, mumbai, india]</td>\n",
       "      <td>[dont, know, old, mumbai, india]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://instagram.fftw1-1.fna.fbcdn.net/vp/808...</td>\n",
       "      <td>“I resented my mother for the longest time. Sh...</td>\n",
       "      <td>hand finger nail arm jewellery ring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York City Sadhana H. Varshney Mumbai Human...</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>237</td>\n",
       "      <td>1201</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, resented, my, mother, for, the, longest, t...</td>\n",
       "      <td>[resented, mother, longest, time, always, affe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           image_url  \\\n",
       "0  https://instagram.fftw1-1.fna.fbcdn.net/vp/e49...   \n",
       "1  https://instagram.fftw1-1.fna.fbcdn.net/vp/2ea...   \n",
       "2  https://instagram.fftw1-1.fna.fbcdn.net/vp/158...   \n",
       "3  https://instagram.fftw1-1.fna.fbcdn.net/vp/053...   \n",
       "4  https://instagram.fftw1-1.fna.fbcdn.net/vp/808...   \n",
       "\n",
       "                                                post  \\\n",
       "0  “I didn’t get accepted into any of the univers...   \n",
       "1  \"I'm trying to live my life without conflict s...   \n",
       "2  “I was a full time housewife. I kept mostly to...   \n",
       "3       \"I don't know how old I am.\" (Mumbai, India)   \n",
       "4  “I resented my mother for the longest time. Sh...   \n",
       "\n",
       "                                        image_labels image_text  \\\n",
       "0  footwear fashion accessory jeans shoulder shoe...        NaN   \n",
       "1  sitting vehicle temple headgear street health ...        NaN   \n",
       "2  woman facial expression lady smile snapshot gi...        NaN   \n",
       "3  face facial expression yellow head smile eye t...        NaN   \n",
       "4                hand finger nail arm jewellery ring        NaN   \n",
       "\n",
       "                                        web_entities       location  likes  \\\n",
       "0  Casa Adela Brandon Stanton New York City Bingh...  Mumbai, India    493   \n",
       "1  Brandon Stanton New York City India Black Pant...  Mumbai, India    268   \n",
       "2  New York City Felines of New York: A Glimpse I...  Mumbai, India    411   \n",
       "3  India Humans of New York Humans of New York: S...  Mumbai, India    451   \n",
       "4  New York City Sadhana H. Varshney Mumbai Human...  Mumbai, India    237   \n",
       "\n",
       "  comments  likes_decile                                              words  \\\n",
       "0     3806             4  [i, didnt, get, accepted, into, any, of, the, ...   \n",
       "1     2714             2  [im, trying, to, live, my, life, without, conf...   \n",
       "2     4103             3  [i, was, a, full, time, housewife, i, kept, mo...   \n",
       "3     5207             3    [i, dont, know, how, old, i, am, mumbai, india]   \n",
       "4     1201             1  [i, resented, my, mother, for, the, longest, t...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [didnt, get, accepted, universities, wanted, e...  \n",
       "1  [im, trying, live, life, without, conflict, do...  \n",
       "2  [full, time, housewife, kept, mostly, shy, per...  \n",
       "3                   [dont, know, old, mumbai, india]  \n",
       "4  [resented, mother, longest, time, always, affe...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df['no_likes'], df['no_comments']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, gensim\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "def get_corpus(tokens):\n",
    "    dictionary = corpora.Dictionary(tokens)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in tokens]\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-01 10:35:37,241 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-03-01 10:35:37,345 : INFO : built Dictionary(5366 unique tokens: [u'inning', u'wetlands', u'exams', u'todays', u'chile']...) from 597 documents (total 38136 corpus positions)\n",
      "2018-03-01 10:35:37,442 : INFO : using symmetric alpha at 0.1\n",
      "2018-03-01 10:35:37,444 : INFO : using symmetric eta at 0.000186358553858\n",
      "2018-03-01 10:35:37,447 : INFO : using serial LDA version on this node\n",
      "2018-03-01 10:35:37,700 : INFO : running online (multi-pass) LDA training, 10 topics, 20 passes over the supplied corpus of 597 documents, updating model once every 597 documents, evaluating perplexity every 597 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2018-03-01 10:35:40,527 : INFO : -10.831 per-word bound, 1821.2 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:35:40,528 : INFO : PROGRESS: pass 0, at document #597/597\n",
      "2018-03-01 10:35:41,429 : INFO : topic #2 (0.100): 0.012*\"get\" + 0.009*\"dont\" + 0.007*\"time\" + 0.006*\"people\" + 0.005*\"started\" + 0.005*\"think\" + 0.005*\"go\" + 0.004*\"day\" + 0.004*\"would\" + 0.004*\"everything\"\n",
      "2018-03-01 10:35:41,430 : INFO : topic #8 (0.100): 0.010*\"always\" + 0.007*\"time\" + 0.006*\"still\" + 0.005*\"dont\" + 0.005*\"years\" + 0.005*\"people\" + 0.005*\"told\" + 0.005*\"us\" + 0.005*\"made\" + 0.005*\"make\"\n",
      "2018-03-01 10:35:41,431 : INFO : topic #5 (0.100): 0.009*\"always\" + 0.008*\"dont\" + 0.008*\"didnt\" + 0.007*\"get\" + 0.007*\"people\" + 0.007*\"school\" + 0.006*\"first\" + 0.005*\"life\" + 0.005*\"work\" + 0.005*\"know\"\n",
      "2018-03-01 10:35:41,433 : INFO : topic #9 (0.100): 0.010*\"time\" + 0.006*\"always\" + 0.006*\"make\" + 0.005*\"want\" + 0.005*\"much\" + 0.005*\"family\" + 0.005*\"go\" + 0.004*\"first\" + 0.004*\"years\" + 0.004*\"people\"\n",
      "2018-03-01 10:35:41,434 : INFO : topic #4 (0.100): 0.008*\"time\" + 0.006*\"told\" + 0.006*\"never\" + 0.005*\"always\" + 0.005*\"us\" + 0.005*\"thought\" + 0.004*\"theyre\" + 0.004*\"everything\" + 0.004*\"years\" + 0.004*\"didnt\"\n",
      "2018-03-01 10:35:41,435 : INFO : topic diff=5.097364, rho=1.000000\n",
      "2018-03-01 10:35:43,414 : INFO : -8.219 per-word bound, 297.9 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:35:43,415 : INFO : PROGRESS: pass 1, at document #597/597\n",
      "2018-03-01 10:35:44,078 : INFO : topic #4 (0.100): 0.007*\"time\" + 0.006*\"told\" + 0.006*\"never\" + 0.006*\"thought\" + 0.005*\"everything\" + 0.005*\"theyre\" + 0.005*\"us\" + 0.004*\"much\" + 0.004*\"always\" + 0.004*\"cant\"\n",
      "2018-03-01 10:35:44,079 : INFO : topic #6 (0.100): 0.010*\"always\" + 0.008*\"never\" + 0.008*\"time\" + 0.007*\"people\" + 0.007*\"feel\" + 0.006*\"get\" + 0.006*\"dont\" + 0.006*\"love\" + 0.005*\"would\" + 0.005*\"could\"\n",
      "2018-03-01 10:35:44,080 : INFO : topic #1 (0.100): 0.009*\"ill\" + 0.009*\"want\" + 0.009*\"time\" + 0.008*\"make\" + 0.008*\"years\" + 0.007*\"told\" + 0.006*\"money\" + 0.005*\"made\" + 0.005*\"wonderful\" + 0.005*\"school\"\n",
      "2018-03-01 10:35:44,081 : INFO : topic #2 (0.100): 0.012*\"get\" + 0.009*\"dont\" + 0.007*\"time\" + 0.006*\"started\" + 0.006*\"people\" + 0.005*\"think\" + 0.005*\"lot\" + 0.005*\"go\" + 0.005*\"would\" + 0.005*\"day\"\n",
      "2018-03-01 10:35:44,082 : INFO : topic #0 (0.100): 0.009*\"dont\" + 0.008*\"didnt\" + 0.007*\"know\" + 0.007*\"people\" + 0.007*\"started\" + 0.006*\"want\" + 0.006*\"things\" + 0.006*\"feel\" + 0.006*\"get\" + 0.006*\"think\"\n",
      "2018-03-01 10:35:44,084 : INFO : topic diff=0.771600, rho=0.577350\n",
      "2018-03-01 10:35:46,069 : INFO : -7.968 per-word bound, 250.4 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:35:46,070 : INFO : PROGRESS: pass 2, at document #597/597\n",
      "2018-03-01 10:35:46,575 : INFO : topic #8 (0.100): 0.011*\"always\" + 0.008*\"years\" + 0.007*\"told\" + 0.007*\"still\" + 0.006*\"time\" + 0.006*\"didnt\" + 0.006*\"make\" + 0.005*\"dont\" + 0.005*\"us\" + 0.005*\"could\"\n",
      "2018-03-01 10:35:46,576 : INFO : topic #0 (0.100): 0.009*\"dont\" + 0.007*\"didnt\" + 0.007*\"know\" + 0.007*\"people\" + 0.007*\"want\" + 0.007*\"things\" + 0.006*\"started\" + 0.006*\"feel\" + 0.006*\"get\" + 0.006*\"think\"\n",
      "2018-03-01 10:35:46,577 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"dont\" + 0.006*\"life\" + 0.006*\"people\" + 0.006*\"get\" + 0.006*\"every\" + 0.006*\"work\" + 0.006*\"didnt\" + 0.005*\"brazil\"\n",
      "2018-03-01 10:35:46,578 : INFO : topic #4 (0.100): 0.007*\"time\" + 0.006*\"never\" + 0.006*\"thought\" + 0.006*\"told\" + 0.005*\"theyre\" + 0.005*\"everything\" + 0.005*\"stories\" + 0.005*\"us\" + 0.005*\"get\" + 0.005*\"fight\"\n",
      "2018-03-01 10:35:46,579 : INFO : topic #6 (0.100): 0.010*\"always\" + 0.009*\"never\" + 0.008*\"time\" + 0.007*\"people\" + 0.007*\"get\" + 0.007*\"dont\" + 0.007*\"feel\" + 0.006*\"love\" + 0.005*\"would\" + 0.005*\"lot\"\n",
      "2018-03-01 10:35:46,581 : INFO : topic diff=0.554220, rho=0.500000\n",
      "2018-03-01 10:35:48,637 : INFO : -7.865 per-word bound, 233.1 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:35:48,638 : INFO : PROGRESS: pass 3, at document #597/597\n",
      "2018-03-01 10:35:49,296 : INFO : topic #9 (0.100): 0.011*\"time\" + 0.006*\"today\" + 0.006*\"want\" + 0.006*\"first\" + 0.006*\"new\" + 0.005*\"lost\" + 0.005*\"go\" + 0.005*\"make\" + 0.005*\"family\" + 0.005*\"ill\"\n",
      "2018-03-01 10:35:49,298 : INFO : topic #8 (0.100): 0.011*\"always\" + 0.008*\"years\" + 0.007*\"told\" + 0.007*\"still\" + 0.006*\"time\" + 0.006*\"didnt\" + 0.006*\"make\" + 0.006*\"dont\" + 0.005*\"could\" + 0.005*\"us\"\n",
      "2018-03-01 10:35:49,300 : INFO : topic #4 (0.100): 0.006*\"time\" + 0.006*\"never\" + 0.006*\"thought\" + 0.006*\"stories\" + 0.005*\"told\" + 0.005*\"theyre\" + 0.005*\"everything\" + 0.005*\"get\" + 0.005*\"us\" + 0.005*\"fight\"\n",
      "2018-03-01 10:35:49,302 : INFO : topic #0 (0.100): 0.009*\"dont\" + 0.008*\"know\" + 0.007*\"didnt\" + 0.007*\"people\" + 0.007*\"things\" + 0.007*\"want\" + 0.006*\"started\" + 0.006*\"get\" + 0.006*\"feel\" + 0.006*\"think\"\n",
      "2018-03-01 10:35:49,304 : INFO : topic #3 (0.100): 0.011*\"people\" + 0.007*\"time\" + 0.007*\"years\" + 0.007*\"think\" + 0.006*\"dont\" + 0.006*\"lot\" + 0.006*\"make\" + 0.006*\"always\" + 0.006*\"every\" + 0.006*\"cant\"\n",
      "2018-03-01 10:35:49,305 : INFO : topic diff=0.396515, rho=0.447214\n",
      "2018-03-01 10:35:50,848 : INFO : -7.816 per-word bound, 225.3 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:35:50,849 : INFO : PROGRESS: pass 4, at document #597/597\n",
      "2018-03-01 10:35:51,313 : INFO : topic #7 (0.100): 0.008*\"didnt\" + 0.008*\"time\" + 0.008*\"never\" + 0.008*\"years\" + 0.007*\"life\" + 0.007*\"get\" + 0.006*\"told\" + 0.006*\"people\" + 0.006*\"us\" + 0.006*\"go\"\n",
      "2018-03-01 10:35:51,314 : INFO : topic #9 (0.100): 0.011*\"time\" + 0.007*\"today\" + 0.006*\"want\" + 0.006*\"new\" + 0.006*\"first\" + 0.006*\"lost\" + 0.005*\"go\" + 0.005*\"make\" + 0.005*\"ill\" + 0.005*\"family\"\n",
      "2018-03-01 10:35:51,316 : INFO : topic #0 (0.100): 0.010*\"dont\" + 0.008*\"know\" + 0.007*\"didnt\" + 0.007*\"things\" + 0.007*\"people\" + 0.007*\"want\" + 0.006*\"started\" + 0.006*\"think\" + 0.006*\"get\" + 0.006*\"feel\"\n",
      "2018-03-01 10:35:51,317 : INFO : topic #6 (0.100): 0.010*\"always\" + 0.009*\"never\" + 0.008*\"time\" + 0.008*\"people\" + 0.007*\"dont\" + 0.007*\"get\" + 0.007*\"love\" + 0.007*\"feel\" + 0.005*\"lot\" + 0.005*\"things\"\n",
      "2018-03-01 10:35:51,318 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"every\" + 0.007*\"life\" + 0.006*\"dont\" + 0.006*\"get\" + 0.006*\"people\" + 0.006*\"brazil\" + 0.006*\"work\" + 0.005*\"time\"\n",
      "2018-03-01 10:35:51,320 : INFO : topic diff=0.283606, rho=0.408248\n",
      "2018-03-01 10:35:52,970 : INFO : -7.790 per-word bound, 221.3 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:35:52,971 : INFO : PROGRESS: pass 5, at document #597/597\n",
      "2018-03-01 10:35:53,574 : INFO : topic #3 (0.100): 0.011*\"people\" + 0.007*\"time\" + 0.007*\"years\" + 0.006*\"dont\" + 0.006*\"think\" + 0.006*\"lot\" + 0.006*\"make\" + 0.006*\"every\" + 0.006*\"cant\" + 0.006*\"always\"\n",
      "2018-03-01 10:35:53,575 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"every\" + 0.007*\"life\" + 0.006*\"dont\" + 0.006*\"get\" + 0.006*\"brazil\" + 0.006*\"people\" + 0.006*\"work\" + 0.005*\"time\"\n",
      "2018-03-01 10:35:53,576 : INFO : topic #7 (0.100): 0.008*\"time\" + 0.008*\"didnt\" + 0.008*\"never\" + 0.008*\"years\" + 0.007*\"life\" + 0.007*\"get\" + 0.007*\"told\" + 0.006*\"us\" + 0.006*\"people\" + 0.006*\"could\"\n",
      "2018-03-01 10:35:53,577 : INFO : topic #8 (0.100): 0.011*\"always\" + 0.008*\"years\" + 0.007*\"told\" + 0.007*\"still\" + 0.006*\"didnt\" + 0.006*\"time\" + 0.006*\"make\" + 0.006*\"dont\" + 0.006*\"could\" + 0.006*\"mom\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-01 10:35:53,579 : INFO : topic #9 (0.100): 0.011*\"time\" + 0.007*\"today\" + 0.006*\"want\" + 0.006*\"new\" + 0.006*\"first\" + 0.006*\"lost\" + 0.005*\"go\" + 0.005*\"make\" + 0.005*\"ill\" + 0.005*\"microfashion\"\n",
      "2018-03-01 10:35:53,580 : INFO : topic diff=0.203769, rho=0.377964\n",
      "2018-03-01 10:35:55,408 : INFO : -7.774 per-word bound, 218.9 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:35:55,409 : INFO : PROGRESS: pass 6, at document #597/597\n",
      "2018-03-01 10:35:56,024 : INFO : topic #7 (0.100): 0.008*\"time\" + 0.008*\"didnt\" + 0.008*\"never\" + 0.008*\"years\" + 0.007*\"life\" + 0.007*\"get\" + 0.007*\"told\" + 0.006*\"us\" + 0.006*\"people\" + 0.006*\"could\"\n",
      "2018-03-01 10:35:56,026 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"every\" + 0.007*\"life\" + 0.006*\"brazil\" + 0.006*\"dont\" + 0.006*\"get\" + 0.006*\"people\" + 0.006*\"work\" + 0.005*\"time\"\n",
      "2018-03-01 10:35:56,028 : INFO : topic #0 (0.100): 0.010*\"dont\" + 0.008*\"know\" + 0.007*\"didnt\" + 0.007*\"things\" + 0.007*\"people\" + 0.007*\"think\" + 0.007*\"want\" + 0.006*\"get\" + 0.006*\"feel\" + 0.006*\"started\"\n",
      "2018-03-01 10:35:56,030 : INFO : topic #6 (0.100): 0.010*\"always\" + 0.009*\"never\" + 0.008*\"time\" + 0.008*\"people\" + 0.007*\"dont\" + 0.007*\"get\" + 0.007*\"love\" + 0.007*\"feel\" + 0.005*\"lot\" + 0.005*\"theyre\"\n",
      "2018-03-01 10:35:56,031 : INFO : topic #9 (0.100): 0.011*\"time\" + 0.007*\"today\" + 0.006*\"want\" + 0.006*\"new\" + 0.006*\"first\" + 0.006*\"lost\" + 0.005*\"go\" + 0.005*\"make\" + 0.005*\"ill\" + 0.005*\"microfashion\"\n",
      "2018-03-01 10:35:56,033 : INFO : topic diff=0.147727, rho=0.353553\n",
      "2018-03-01 10:35:57,729 : INFO : -7.764 per-word bound, 217.4 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:35:57,730 : INFO : PROGRESS: pass 7, at document #597/597\n",
      "2018-03-01 10:35:58,169 : INFO : topic #8 (0.100): 0.011*\"always\" + 0.008*\"years\" + 0.007*\"told\" + 0.007*\"still\" + 0.006*\"didnt\" + 0.006*\"make\" + 0.006*\"time\" + 0.006*\"dont\" + 0.006*\"could\" + 0.006*\"mom\"\n",
      "2018-03-01 10:35:58,170 : INFO : topic #9 (0.100): 0.011*\"time\" + 0.007*\"today\" + 0.006*\"want\" + 0.006*\"new\" + 0.006*\"first\" + 0.006*\"lost\" + 0.005*\"go\" + 0.005*\"make\" + 0.005*\"ill\" + 0.005*\"microfashion\"\n",
      "2018-03-01 10:35:58,171 : INFO : topic #0 (0.100): 0.010*\"dont\" + 0.008*\"know\" + 0.007*\"didnt\" + 0.007*\"things\" + 0.007*\"people\" + 0.007*\"think\" + 0.007*\"want\" + 0.006*\"feel\" + 0.006*\"get\" + 0.006*\"started\"\n",
      "2018-03-01 10:35:58,172 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"every\" + 0.007*\"life\" + 0.006*\"brazil\" + 0.006*\"dont\" + 0.006*\"get\" + 0.006*\"people\" + 0.006*\"work\" + 0.005*\"time\"\n",
      "2018-03-01 10:35:58,173 : INFO : topic #1 (0.100): 0.012*\"want\" + 0.010*\"make\" + 0.010*\"ill\" + 0.010*\"told\" + 0.009*\"years\" + 0.009*\"time\" + 0.008*\"money\" + 0.008*\"school\" + 0.007*\"made\" + 0.007*\"feel\"\n",
      "2018-03-01 10:35:58,174 : INFO : topic diff=0.108266, rho=0.333333\n",
      "2018-03-01 10:35:59,682 : INFO : -7.757 per-word bound, 216.3 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:35:59,683 : INFO : PROGRESS: pass 8, at document #597/597\n",
      "2018-03-01 10:36:00,117 : INFO : topic #7 (0.100): 0.008*\"time\" + 0.008*\"didnt\" + 0.008*\"never\" + 0.008*\"years\" + 0.007*\"life\" + 0.007*\"get\" + 0.007*\"told\" + 0.006*\"us\" + 0.006*\"people\" + 0.006*\"could\"\n",
      "2018-03-01 10:36:00,118 : INFO : topic #6 (0.100): 0.010*\"always\" + 0.009*\"never\" + 0.008*\"time\" + 0.008*\"people\" + 0.007*\"dont\" + 0.007*\"love\" + 0.007*\"get\" + 0.007*\"feel\" + 0.005*\"lot\" + 0.005*\"theyre\"\n",
      "2018-03-01 10:36:00,119 : INFO : topic #0 (0.100): 0.010*\"dont\" + 0.008*\"know\" + 0.007*\"didnt\" + 0.007*\"things\" + 0.007*\"think\" + 0.007*\"people\" + 0.007*\"want\" + 0.007*\"feel\" + 0.006*\"get\" + 0.006*\"started\"\n",
      "2018-03-01 10:36:00,120 : INFO : topic #8 (0.100): 0.011*\"always\" + 0.008*\"years\" + 0.007*\"told\" + 0.007*\"still\" + 0.006*\"didnt\" + 0.006*\"make\" + 0.006*\"dont\" + 0.006*\"time\" + 0.006*\"mom\" + 0.006*\"could\"\n",
      "2018-03-01 10:36:00,121 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"every\" + 0.007*\"life\" + 0.006*\"brazil\" + 0.006*\"dont\" + 0.006*\"get\" + 0.006*\"people\" + 0.006*\"work\" + 0.005*\"time\"\n",
      "2018-03-01 10:36:00,122 : INFO : topic diff=0.080541, rho=0.316228\n",
      "2018-03-01 10:36:01,566 : INFO : -7.752 per-word bound, 215.6 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:36:01,567 : INFO : PROGRESS: pass 9, at document #597/597\n",
      "2018-03-01 10:36:01,992 : INFO : topic #6 (0.100): 0.010*\"always\" + 0.009*\"never\" + 0.008*\"time\" + 0.008*\"people\" + 0.007*\"dont\" + 0.007*\"love\" + 0.007*\"get\" + 0.006*\"feel\" + 0.005*\"lot\" + 0.005*\"theyre\"\n",
      "2018-03-01 10:36:01,993 : INFO : topic #3 (0.100): 0.011*\"people\" + 0.007*\"time\" + 0.007*\"years\" + 0.006*\"dont\" + 0.006*\"think\" + 0.006*\"make\" + 0.006*\"cant\" + 0.006*\"lot\" + 0.006*\"every\" + 0.006*\"day\"\n",
      "2018-03-01 10:36:01,994 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"every\" + 0.007*\"life\" + 0.007*\"brazil\" + 0.006*\"get\" + 0.006*\"dont\" + 0.006*\"people\" + 0.006*\"work\" + 0.005*\"time\"\n",
      "2018-03-01 10:36:01,996 : INFO : topic #1 (0.100): 0.012*\"want\" + 0.010*\"make\" + 0.010*\"ill\" + 0.010*\"told\" + 0.009*\"years\" + 0.009*\"time\" + 0.008*\"money\" + 0.008*\"school\" + 0.007*\"feel\" + 0.007*\"made\"\n",
      "2018-03-01 10:36:01,997 : INFO : topic #7 (0.100): 0.008*\"time\" + 0.008*\"didnt\" + 0.008*\"never\" + 0.008*\"years\" + 0.007*\"life\" + 0.007*\"get\" + 0.007*\"told\" + 0.006*\"us\" + 0.006*\"people\" + 0.006*\"could\"\n",
      "2018-03-01 10:36:01,998 : INFO : topic diff=0.060918, rho=0.301511\n",
      "2018-03-01 10:36:03,840 : INFO : -7.749 per-word bound, 215.1 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:36:03,841 : INFO : PROGRESS: pass 10, at document #597/597\n",
      "2018-03-01 10:36:04,363 : INFO : topic #2 (0.100): 0.012*\"get\" + 0.011*\"dont\" + 0.007*\"time\" + 0.006*\"people\" + 0.006*\"lot\" + 0.006*\"think\" + 0.006*\"started\" + 0.005*\"would\" + 0.005*\"shes\" + 0.005*\"money\"\n",
      "2018-03-01 10:36:04,364 : INFO : topic #1 (0.100): 0.012*\"want\" + 0.010*\"make\" + 0.010*\"ill\" + 0.010*\"told\" + 0.009*\"years\" + 0.008*\"time\" + 0.008*\"money\" + 0.008*\"school\" + 0.007*\"feel\" + 0.007*\"made\"\n",
      "2018-03-01 10:36:04,365 : INFO : topic #6 (0.100): 0.010*\"always\" + 0.009*\"never\" + 0.008*\"time\" + 0.008*\"people\" + 0.007*\"dont\" + 0.007*\"love\" + 0.007*\"get\" + 0.006*\"feel\" + 0.005*\"lot\" + 0.005*\"theyre\"\n",
      "2018-03-01 10:36:04,367 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"every\" + 0.007*\"life\" + 0.007*\"brazil\" + 0.006*\"get\" + 0.006*\"dont\" + 0.006*\"people\" + 0.006*\"work\" + 0.005*\"time\"\n",
      "2018-03-01 10:36:04,368 : INFO : topic #9 (0.100): 0.011*\"time\" + 0.007*\"today\" + 0.006*\"new\" + 0.006*\"want\" + 0.006*\"first\" + 0.006*\"lost\" + 0.005*\"make\" + 0.005*\"go\" + 0.005*\"microfashion\" + 0.005*\"ill\"\n",
      "2018-03-01 10:36:04,368 : INFO : topic diff=0.046939, rho=0.288675\n",
      "2018-03-01 10:36:06,202 : INFO : -7.746 per-word bound, 214.6 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:36:06,203 : INFO : PROGRESS: pass 11, at document #597/597\n",
      "2018-03-01 10:36:06,725 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"every\" + 0.007*\"brazil\" + 0.007*\"life\" + 0.006*\"get\" + 0.006*\"people\" + 0.006*\"dont\" + 0.006*\"work\" + 0.005*\"time\"\n",
      "2018-03-01 10:36:06,727 : INFO : topic #0 (0.100): 0.010*\"dont\" + 0.008*\"know\" + 0.007*\"didnt\" + 0.007*\"things\" + 0.007*\"think\" + 0.007*\"want\" + 0.007*\"feel\" + 0.007*\"people\" + 0.007*\"get\" + 0.006*\"started\"\n",
      "2018-03-01 10:36:06,727 : INFO : topic #6 (0.100): 0.010*\"always\" + 0.009*\"never\" + 0.008*\"time\" + 0.008*\"people\" + 0.007*\"dont\" + 0.007*\"love\" + 0.007*\"get\" + 0.006*\"feel\" + 0.005*\"lot\" + 0.005*\"theyre\"\n",
      "2018-03-01 10:36:06,728 : INFO : topic #3 (0.100): 0.011*\"people\" + 0.007*\"time\" + 0.007*\"years\" + 0.006*\"dont\" + 0.006*\"make\" + 0.006*\"cant\" + 0.006*\"think\" + 0.006*\"every\" + 0.006*\"lot\" + 0.006*\"day\"\n",
      "2018-03-01 10:36:06,730 : INFO : topic #4 (0.100): 0.007*\"stories\" + 0.007*\"thought\" + 0.006*\"never\" + 0.005*\"everything\" + 0.005*\"theyre\" + 0.005*\"time\" + 0.005*\"two\" + 0.005*\"fight\" + 0.005*\"war\" + 0.005*\"get\"\n",
      "2018-03-01 10:36:06,731 : INFO : topic diff=0.036808, rho=0.277350\n",
      "2018-03-01 10:36:08,889 : INFO : -7.743 per-word bound, 214.3 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-01 10:36:08,889 : INFO : PROGRESS: pass 12, at document #597/597\n",
      "2018-03-01 10:36:09,370 : INFO : topic #8 (0.100): 0.012*\"always\" + 0.008*\"years\" + 0.007*\"told\" + 0.007*\"still\" + 0.006*\"didnt\" + 0.006*\"make\" + 0.006*\"dont\" + 0.006*\"time\" + 0.006*\"mom\" + 0.006*\"could\"\n",
      "2018-03-01 10:36:09,371 : INFO : topic #6 (0.100): 0.010*\"always\" + 0.009*\"never\" + 0.008*\"time\" + 0.008*\"people\" + 0.007*\"dont\" + 0.007*\"love\" + 0.007*\"get\" + 0.006*\"feel\" + 0.005*\"lot\" + 0.005*\"theyre\"\n",
      "2018-03-01 10:36:09,372 : INFO : topic #2 (0.100): 0.012*\"get\" + 0.011*\"dont\" + 0.007*\"time\" + 0.006*\"people\" + 0.006*\"lot\" + 0.006*\"think\" + 0.005*\"started\" + 0.005*\"would\" + 0.005*\"shes\" + 0.005*\"money\"\n",
      "2018-03-01 10:36:09,374 : INFO : topic #1 (0.100): 0.012*\"want\" + 0.010*\"make\" + 0.010*\"ill\" + 0.010*\"told\" + 0.009*\"years\" + 0.008*\"time\" + 0.008*\"money\" + 0.008*\"school\" + 0.007*\"feel\" + 0.007*\"made\"\n",
      "2018-03-01 10:36:09,375 : INFO : topic #7 (0.100): 0.009*\"time\" + 0.008*\"didnt\" + 0.008*\"years\" + 0.008*\"never\" + 0.007*\"life\" + 0.007*\"get\" + 0.007*\"told\" + 0.006*\"us\" + 0.006*\"could\" + 0.006*\"people\"\n",
      "2018-03-01 10:36:09,376 : INFO : topic diff=0.029431, rho=0.267261\n",
      "2018-03-01 10:36:11,391 : INFO : -7.741 per-word bound, 214.0 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:36:11,392 : INFO : PROGRESS: pass 13, at document #597/597\n",
      "2018-03-01 10:36:11,928 : INFO : topic #1 (0.100): 0.012*\"want\" + 0.010*\"make\" + 0.010*\"ill\" + 0.010*\"told\" + 0.009*\"years\" + 0.008*\"time\" + 0.008*\"money\" + 0.008*\"school\" + 0.007*\"feel\" + 0.007*\"made\"\n",
      "2018-03-01 10:36:11,929 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"every\" + 0.007*\"brazil\" + 0.007*\"life\" + 0.006*\"get\" + 0.006*\"people\" + 0.006*\"dont\" + 0.006*\"work\" + 0.005*\"time\"\n",
      "2018-03-01 10:36:11,931 : INFO : topic #0 (0.100): 0.010*\"dont\" + 0.008*\"know\" + 0.007*\"didnt\" + 0.007*\"think\" + 0.007*\"things\" + 0.007*\"want\" + 0.007*\"feel\" + 0.007*\"people\" + 0.007*\"get\" + 0.006*\"started\"\n",
      "2018-03-01 10:36:11,932 : INFO : topic #4 (0.100): 0.007*\"stories\" + 0.007*\"thought\" + 0.005*\"everything\" + 0.005*\"theyre\" + 0.005*\"never\" + 0.005*\"fight\" + 0.005*\"two\" + 0.005*\"time\" + 0.005*\"war\" + 0.005*\"get\"\n",
      "2018-03-01 10:36:11,934 : INFO : topic #8 (0.100): 0.012*\"always\" + 0.008*\"years\" + 0.007*\"told\" + 0.007*\"still\" + 0.006*\"didnt\" + 0.006*\"make\" + 0.006*\"dont\" + 0.006*\"time\" + 0.006*\"mom\" + 0.006*\"could\"\n",
      "2018-03-01 10:36:11,936 : INFO : topic diff=0.023954, rho=0.258199\n",
      "2018-03-01 10:36:13,611 : INFO : -7.740 per-word bound, 213.7 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:36:13,612 : INFO : PROGRESS: pass 14, at document #597/597\n",
      "2018-03-01 10:36:14,208 : INFO : topic #9 (0.100): 0.011*\"time\" + 0.007*\"today\" + 0.006*\"new\" + 0.006*\"want\" + 0.006*\"first\" + 0.006*\"lost\" + 0.005*\"make\" + 0.005*\"microfashion\" + 0.005*\"go\" + 0.005*\"ill\"\n",
      "2018-03-01 10:36:14,210 : INFO : topic #1 (0.100): 0.012*\"want\" + 0.010*\"make\" + 0.010*\"ill\" + 0.010*\"told\" + 0.009*\"years\" + 0.008*\"money\" + 0.008*\"time\" + 0.008*\"school\" + 0.007*\"feel\" + 0.007*\"made\"\n",
      "2018-03-01 10:36:14,211 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"every\" + 0.007*\"brazil\" + 0.007*\"life\" + 0.006*\"people\" + 0.006*\"get\" + 0.006*\"dont\" + 0.005*\"time\" + 0.005*\"work\"\n",
      "2018-03-01 10:36:14,212 : INFO : topic #7 (0.100): 0.009*\"time\" + 0.008*\"didnt\" + 0.008*\"years\" + 0.008*\"never\" + 0.007*\"life\" + 0.007*\"get\" + 0.007*\"told\" + 0.007*\"us\" + 0.006*\"could\" + 0.006*\"people\"\n",
      "2018-03-01 10:36:14,214 : INFO : topic #6 (0.100): 0.010*\"always\" + 0.008*\"never\" + 0.008*\"time\" + 0.008*\"people\" + 0.007*\"dont\" + 0.007*\"love\" + 0.007*\"get\" + 0.006*\"feel\" + 0.005*\"lot\" + 0.005*\"theyre\"\n",
      "2018-03-01 10:36:14,215 : INFO : topic diff=0.019826, rho=0.250000\n",
      "2018-03-01 10:36:16,546 : INFO : -7.738 per-word bound, 213.5 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:36:16,547 : INFO : PROGRESS: pass 15, at document #597/597\n",
      "2018-03-01 10:36:17,054 : INFO : topic #9 (0.100): 0.011*\"time\" + 0.007*\"today\" + 0.006*\"new\" + 0.006*\"first\" + 0.006*\"want\" + 0.006*\"lost\" + 0.005*\"make\" + 0.005*\"microfashion\" + 0.005*\"ill\" + 0.005*\"india\"\n",
      "2018-03-01 10:36:17,055 : INFO : topic #4 (0.100): 0.008*\"stories\" + 0.007*\"thought\" + 0.005*\"everything\" + 0.005*\"theyre\" + 0.005*\"never\" + 0.005*\"fight\" + 0.005*\"two\" + 0.005*\"war\" + 0.005*\"time\" + 0.005*\"cant\"\n",
      "2018-03-01 10:36:17,056 : INFO : topic #1 (0.100): 0.012*\"want\" + 0.011*\"make\" + 0.010*\"ill\" + 0.010*\"told\" + 0.009*\"years\" + 0.008*\"money\" + 0.008*\"time\" + 0.008*\"school\" + 0.007*\"feel\" + 0.007*\"made\"\n",
      "2018-03-01 10:36:17,058 : INFO : topic #7 (0.100): 0.009*\"time\" + 0.008*\"years\" + 0.008*\"didnt\" + 0.008*\"never\" + 0.007*\"life\" + 0.007*\"get\" + 0.007*\"told\" + 0.007*\"us\" + 0.006*\"could\" + 0.006*\"people\"\n",
      "2018-03-01 10:36:17,059 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"brazil\" + 0.007*\"every\" + 0.007*\"life\" + 0.006*\"people\" + 0.006*\"get\" + 0.006*\"time\" + 0.005*\"dont\" + 0.005*\"work\"\n",
      "2018-03-01 10:36:17,060 : INFO : topic diff=0.016660, rho=0.242536\n",
      "2018-03-01 10:36:18,912 : INFO : -7.736 per-word bound, 213.3 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:36:18,913 : INFO : PROGRESS: pass 16, at document #597/597\n",
      "2018-03-01 10:36:19,373 : INFO : topic #2 (0.100): 0.012*\"get\" + 0.011*\"dont\" + 0.007*\"time\" + 0.006*\"people\" + 0.006*\"lot\" + 0.006*\"think\" + 0.005*\"started\" + 0.005*\"would\" + 0.005*\"shes\" + 0.005*\"money\"\n",
      "2018-03-01 10:36:19,375 : INFO : topic #7 (0.100): 0.009*\"time\" + 0.008*\"years\" + 0.008*\"didnt\" + 0.008*\"never\" + 0.007*\"life\" + 0.007*\"get\" + 0.007*\"told\" + 0.007*\"us\" + 0.006*\"people\" + 0.006*\"could\"\n",
      "2018-03-01 10:36:19,376 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"brazil\" + 0.007*\"every\" + 0.007*\"life\" + 0.006*\"people\" + 0.006*\"get\" + 0.006*\"time\" + 0.005*\"work\" + 0.005*\"dont\"\n",
      "2018-03-01 10:36:19,377 : INFO : topic #9 (0.100): 0.011*\"time\" + 0.007*\"today\" + 0.006*\"new\" + 0.006*\"first\" + 0.006*\"want\" + 0.006*\"lost\" + 0.005*\"make\" + 0.005*\"microfashion\" + 0.005*\"india\" + 0.005*\"ill\"\n",
      "2018-03-01 10:36:19,378 : INFO : topic #4 (0.100): 0.008*\"stories\" + 0.007*\"thought\" + 0.006*\"everything\" + 0.005*\"theyre\" + 0.005*\"fight\" + 0.005*\"never\" + 0.005*\"two\" + 0.005*\"war\" + 0.005*\"time\" + 0.005*\"cant\"\n",
      "2018-03-01 10:36:19,380 : INFO : topic diff=0.014184, rho=0.235702\n",
      "2018-03-01 10:36:21,072 : INFO : -7.735 per-word bound, 213.1 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:36:21,074 : INFO : PROGRESS: pass 17, at document #597/597\n",
      "2018-03-01 10:36:21,628 : INFO : topic #8 (0.100): 0.012*\"always\" + 0.008*\"years\" + 0.007*\"told\" + 0.007*\"still\" + 0.006*\"didnt\" + 0.006*\"make\" + 0.006*\"dont\" + 0.006*\"time\" + 0.006*\"mom\" + 0.006*\"could\"\n",
      "2018-03-01 10:36:21,630 : INFO : topic #2 (0.100): 0.012*\"get\" + 0.011*\"dont\" + 0.007*\"time\" + 0.006*\"people\" + 0.006*\"lot\" + 0.006*\"think\" + 0.005*\"started\" + 0.005*\"would\" + 0.005*\"shes\" + 0.005*\"money\"\n",
      "2018-03-01 10:36:21,632 : INFO : topic #3 (0.100): 0.011*\"people\" + 0.007*\"time\" + 0.006*\"years\" + 0.006*\"dont\" + 0.006*\"cant\" + 0.006*\"make\" + 0.006*\"every\" + 0.006*\"lot\" + 0.006*\"think\" + 0.006*\"day\"\n",
      "2018-03-01 10:36:21,633 : INFO : topic #1 (0.100): 0.012*\"want\" + 0.011*\"make\" + 0.010*\"ill\" + 0.010*\"told\" + 0.009*\"years\" + 0.009*\"money\" + 0.008*\"time\" + 0.008*\"school\" + 0.007*\"made\" + 0.007*\"feel\"\n",
      "2018-03-01 10:36:21,635 : INFO : topic #9 (0.100): 0.011*\"time\" + 0.007*\"today\" + 0.006*\"new\" + 0.006*\"first\" + 0.006*\"want\" + 0.006*\"lost\" + 0.005*\"make\" + 0.005*\"microfashion\" + 0.005*\"india\" + 0.005*\"ill\"\n",
      "2018-03-01 10:36:21,637 : INFO : topic diff=0.012249, rho=0.229416\n",
      "2018-03-01 10:36:23,741 : INFO : -7.734 per-word bound, 212.9 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:36:23,742 : INFO : PROGRESS: pass 18, at document #597/597\n",
      "2018-03-01 10:36:24,139 : INFO : topic #6 (0.100): 0.010*\"always\" + 0.008*\"never\" + 0.008*\"people\" + 0.008*\"time\" + 0.007*\"dont\" + 0.007*\"love\" + 0.007*\"get\" + 0.006*\"feel\" + 0.005*\"lot\" + 0.005*\"theyre\"\n",
      "2018-03-01 10:36:24,140 : INFO : topic #2 (0.100): 0.012*\"get\" + 0.011*\"dont\" + 0.007*\"time\" + 0.006*\"people\" + 0.006*\"lot\" + 0.006*\"think\" + 0.005*\"started\" + 0.005*\"would\" + 0.005*\"shes\" + 0.005*\"money\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-01 10:36:24,142 : INFO : topic #4 (0.100): 0.008*\"stories\" + 0.007*\"thought\" + 0.006*\"everything\" + 0.006*\"theyre\" + 0.005*\"fight\" + 0.005*\"never\" + 0.005*\"two\" + 0.005*\"war\" + 0.005*\"cant\" + 0.005*\"time\"\n",
      "2018-03-01 10:36:24,143 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"brazil\" + 0.007*\"every\" + 0.007*\"life\" + 0.006*\"people\" + 0.006*\"get\" + 0.006*\"time\" + 0.005*\"work\" + 0.005*\"day\"\n",
      "2018-03-01 10:36:24,144 : INFO : topic #8 (0.100): 0.012*\"always\" + 0.008*\"years\" + 0.007*\"told\" + 0.007*\"still\" + 0.006*\"didnt\" + 0.006*\"make\" + 0.006*\"dont\" + 0.006*\"time\" + 0.006*\"could\" + 0.006*\"mom\"\n",
      "2018-03-01 10:36:24,145 : INFO : topic diff=0.010722, rho=0.223607\n",
      "2018-03-01 10:36:26,063 : INFO : -7.733 per-word bound, 212.8 perplexity estimate based on a held-out corpus of 597 documents with 38136 words\n",
      "2018-03-01 10:36:26,064 : INFO : PROGRESS: pass 19, at document #597/597\n",
      "2018-03-01 10:36:26,509 : INFO : topic #6 (0.100): 0.010*\"always\" + 0.008*\"never\" + 0.008*\"people\" + 0.008*\"time\" + 0.007*\"dont\" + 0.007*\"love\" + 0.007*\"get\" + 0.006*\"feel\" + 0.005*\"lot\" + 0.005*\"theyre\"\n",
      "2018-03-01 10:36:26,510 : INFO : topic #9 (0.100): 0.011*\"time\" + 0.007*\"today\" + 0.006*\"new\" + 0.006*\"first\" + 0.006*\"want\" + 0.006*\"lost\" + 0.005*\"make\" + 0.005*\"microfashion\" + 0.005*\"india\" + 0.005*\"ill\"\n",
      "2018-03-01 10:36:26,511 : INFO : topic #1 (0.100): 0.012*\"want\" + 0.011*\"make\" + 0.010*\"ill\" + 0.010*\"told\" + 0.009*\"years\" + 0.009*\"money\" + 0.008*\"time\" + 0.008*\"school\" + 0.007*\"made\" + 0.007*\"feel\"\n",
      "2018-03-01 10:36:26,512 : INFO : topic #5 (0.100): 0.011*\"always\" + 0.009*\"school\" + 0.007*\"brazil\" + 0.007*\"every\" + 0.007*\"life\" + 0.006*\"people\" + 0.006*\"get\" + 0.006*\"time\" + 0.005*\"work\" + 0.005*\"day\"\n",
      "2018-03-01 10:36:26,513 : INFO : topic #0 (0.100): 0.010*\"dont\" + 0.008*\"know\" + 0.007*\"didnt\" + 0.007*\"think\" + 0.007*\"things\" + 0.007*\"want\" + 0.007*\"feel\" + 0.007*\"get\" + 0.006*\"people\" + 0.006*\"started\"\n",
      "2018-03-01 10:36:26,514 : INFO : topic diff=0.009505, rho=0.218218\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(sw_token_docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in sw_token_docs]\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "lda = gensim.models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=10, update_every=1, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #  0 (5, u'0.011*\"always\" + 0.009*\"school\" + 0.007*\"brazil\" + 0.007*\"every\" + 0.007*\"life\" + 0.006*\"people\" + 0.006*\"get\" + 0.006*\"time\" + 0.005*\"work\" + 0.005*\"day\" + 0.005*\"de\" + 0.005*\"dont\" + 0.005*\"first\" + 0.005*\"still\" + 0.005*\"janeiro\"')\n",
      "Topic #  1 (6, u'0.010*\"always\" + 0.008*\"never\" + 0.008*\"people\" + 0.008*\"time\" + 0.007*\"dont\" + 0.007*\"love\" + 0.007*\"get\" + 0.006*\"feel\" + 0.005*\"lot\" + 0.005*\"theyre\" + 0.005*\"would\" + 0.005*\"things\" + 0.004*\"want\" + 0.004*\"parents\" + 0.004*\"know\"')\n",
      "Topic #  2 (8, u'0.012*\"always\" + 0.008*\"years\" + 0.007*\"told\" + 0.007*\"still\" + 0.006*\"didnt\" + 0.006*\"make\" + 0.006*\"dont\" + 0.006*\"time\" + 0.006*\"could\" + 0.006*\"mom\" + 0.005*\"school\" + 0.005*\"people\" + 0.005*\"us\" + 0.005*\"know\" + 0.005*\"never\"')\n",
      "Topic #  3 (4, u'0.008*\"stories\" + 0.007*\"thought\" + 0.006*\"everything\" + 0.006*\"theyre\" + 0.005*\"fight\" + 0.005*\"never\" + 0.005*\"two\" + 0.005*\"war\" + 0.005*\"cant\" + 0.005*\"read\" + 0.005*\"time\" + 0.005*\"get\" + 0.005*\"told\" + 0.005*\"cancer\" + 0.005*\"greatest\"')\n",
      "Topic #  4 (1, u'0.012*\"want\" + 0.011*\"make\" + 0.010*\"ill\" + 0.010*\"told\" + 0.009*\"years\" + 0.009*\"money\" + 0.008*\"time\" + 0.008*\"school\" + 0.007*\"made\" + 0.007*\"feel\" + 0.006*\"dont\" + 0.006*\"good\" + 0.006*\"business\" + 0.006*\"wonderful\" + 0.005*\"day\"')\n"
     ]
    }
   ],
   "source": [
    "t=0\n",
    "for i in lda.show_topics(num_topics=5, num_words=15, log=False, formatted=True):\n",
    "    print \"Topic # \", t , i\n",
    "    t = t + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "documentation": "# Enter Documentation Here...",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
